{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text language Detection by using N-Gram\n",
    "\n",
    "Submitted by - Niraj Dev Pandey(271484)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are importing compulsary dependencies that will help us to use the library made for text language recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import operator\n",
    "import string\n",
    "import glob\n",
    "import os.path\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of my code will ask you to enter the location of your file which has text to be detected. \n",
    "\n",
    "If you sum up all the code in one cell then it will works better than it will now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = input(\"Enter the file location: \")\n",
    "fp = open(filename)\n",
    "text = fp.read().decode('utf8')\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making tokens from the file you have entered to be detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = word_tokenize(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gernerate N-Gram for given text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_ngrams=[]\n",
    "for word in words:\n",
    "    for i in range(1,6):\n",
    "        temp = ngrams(word, i, pad_left = True, pad_right = True, left_pad_symbol = ' ', right_pad_symbol =' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the characters of individual N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for t in temp:\n",
    "    ngram = ''.join(t)\n",
    "    gen_ngrams.append(ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are calculating ngram frequencies of the given textfile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngram_stats = {}\n",
    "for n in gen_ngrams:\n",
    "    if not ngram_stats.has_key(n):\n",
    "        ngram_stats.update({n:1})\n",
    "        else:\n",
    "            ng_count = ngram_stats[n]\n",
    "            ngram_stats.update({n:ng_count+1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we are going to sort them, add an iterator to dict and reverse sort based on second column(ngrams counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngrams_txt_sorted = sorted(ngram_stats.iteritems(), key=operator.itemgetter(1), reverse = True)[0:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here Loading ngram language statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lang_stats={}\n",
    "for filepath in glob.glob('./langdata/*.dat'):\n",
    "    filename = os.path.basename(filepath)\n",
    "    lang = os.path.splitext(filename)[0]\n",
    "    ngram_stats = open(filepath,\"r\").readlines()\n",
    "    ngram_stats = [x.rstrip() for x in ngram_stats]\n",
    "    lang_stats.update({lang:ngram_stats})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare ngram frequency statistics by doing a rank order lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lang_ratios = {}\n",
    "txt_ng = [ng[0] for ng in ngrams_txt_sorted]\n",
    "max_out_of_place = len(txt_ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for lang, ngram_stat in lang_stats.iteritems():\n",
    "    lang_ng = [ng[0] for ng in ngram_stat]\n",
    "    doc_dist = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we don't really have to use encode. I mean if there is no such requirment with your given file you can drope it. About the 'file input' in python 3.5 or above it's fine but with 2.7 or older version you can use \"raw_text(file location)\" instead of using \"input(file location)\" function.\n",
    "\n",
    "For more detailed information one can see the 'what's new' section in python 3.5 documentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for n in txt_ng:\n",
    "        try:\n",
    "            txt_ng_index = txt_ng.index(n)\n",
    "            lang_ng_index = lang_ng.index(n.encode('utf8'))\n",
    "            except ValueError:\n",
    "                lang_ng_index = max_out_of_place\n",
    "                doc_dist += abs(lang_ng_index - txt_ng_index)\n",
    "                lang_ratios.update({lang:doc_dist})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in lang_ratios.iteritems():\n",
    "    print (i)\n",
    "predicted_lang = min(lang_ratios, key=lang_ratios.get)\n",
    "print (\"The language is\",predicted_lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you should use this code in one cell only so that you can put your file at the end and it will detect the language of that file. I wrote in this manner just to explain each and every step of my code and for my understanding. I'm also including python file that you can run on your own machine. Thanks "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
